{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN\n",
    "- keras를 이용한 ANN 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "base_path = './xray_classification_pneumonia/Dataset_compressed/train'\n",
    "file_path = list(glob.glob(base_path + \"/*/*.*\"))\n",
    "\n",
    "pneumonia = list(glob.glob(base_path+\"/PNEUMONIA/*.*\"))\n",
    "normal = list(glob.glob(base_path+\"/NORMAL/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3875, 1341)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pneumonia), len(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./xray_classification_pneumonia/Dataset_compressed/train\\NORMAL\n",
      "('./xray_classification_pneumonia/Dataset_compressed', 'train')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "test = os.path.dirname(file_path[0])\n",
    "print(test)\n",
    "class_name = os.path.split(os.path.dirname(test))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name to label\n",
    "labels = []\n",
    "\n",
    "for fp in file_path:\n",
    "    tmp = os.path.dirname(fp)\n",
    "    class_name = os.path.split(tmp)\n",
    "    if class_name[1] == \"PNEUMONIA\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 images to array\n",
      "500 images to array\n",
      "750 images to array\n",
      "1000 images to array\n",
      "1250 images to array\n",
      "1500 images to array\n",
      "1750 images to array\n",
      "2000 images to array\n",
      "2250 images to array\n",
      "2500 images to array\n",
      "2750 images to array\n",
      "3000 images to array\n",
      "3250 images to array\n",
      "3500 images to array\n",
      "3750 images to array\n",
      "4000 images to array\n",
      "4250 images to array\n",
      "4500 images to array\n",
      "4750 images to array\n",
      "5000 images to array\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import cv2\n",
    "\n",
    "\n",
    "img_width = 60\n",
    "img_height = 60\n",
    "\n",
    "dataset = np.ndarray(shape=(len(file_path), img_height*img_width), dtype=np.float32)\n",
    "\n",
    "i=0\n",
    "for _file in file_path:\n",
    "    img = cv2.imread(_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (img_width, img_height))\n",
    "    \n",
    "    dataset[i] = img_resized.flatten()\n",
    "    i += 1\n",
    "    if i % 250 == 0:\n",
    "        print(f\"{i} images to array\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4172, 1044, 4172, 1044)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = map(lambda x: to_categorical(x), [y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               360100    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 365,252\n",
      "Trainable params: 365,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(3600,)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0962368e-28, 9.9999994e-01],\n",
       "       [1.0479997e-21, 9.9999994e-01],\n",
       "       [0.0000000e+00, 9.9999994e-01],\n",
       "       ...,\n",
       "       [4.6451209e-20, 9.9999994e-01],\n",
       "       [0.0000000e+00, 9.9999994e-01],\n",
       "       [7.6988302e-16, 9.9999994e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 31.7285 - accuracy: 0.7951 - val_loss: 1.9673 - val_accuracy: 0.9320\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.1577 - accuracy: 0.8615 - val_loss: 2.9879 - val_accuracy: 0.8918\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.8799 - accuracy: 0.9017 - val_loss: 3.9332 - val_accuracy: 0.8784\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.7164 - accuracy: 0.9358 - val_loss: 1.3544 - val_accuracy: 0.9464\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.0907 - accuracy: 0.9221 - val_loss: 1.3967 - val_accuracy: 0.9511\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 1.1916 - accuracy: 0.9453 - val_loss: 1.4169 - val_accuracy: 0.9387\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.8503 - accuracy: 0.9506 - val_loss: 1.4485 - val_accuracy: 0.9339\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0794 - accuracy: 0.9348 - val_loss: 0.9543 - val_accuracy: 0.9550\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.6177 - accuracy: 0.8672 - val_loss: 3.5605 - val_accuracy: 0.8803\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 1.8869 - accuracy: 0.9322 - val_loss: 2.0562 - val_accuracy: 0.9253\n",
      "Epoch 11/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.8487 - accuracy: 0.9247 - val_loss: 1.5564 - val_accuracy: 0.9301\n",
      "Epoch 12/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3484 - accuracy: 0.9293 - val_loss: 1.2015 - val_accuracy: 0.9425\n",
      "Epoch 13/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.9564 - val_loss: 0.9366 - val_accuracy: 0.9464\n",
      "Epoch 14/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.9573 - val_loss: 0.6133 - val_accuracy: 0.9349\n",
      "Epoch 15/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.9477 - val_loss: 0.7985 - val_accuracy: 0.9406\n",
      "Epoch 16/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.9557 - val_loss: 0.8284 - val_accuracy: 0.9291\n",
      "Epoch 17/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.9465 - val_loss: 0.5058 - val_accuracy: 0.9550\n",
      "Epoch 18/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.9595 - val_loss: 0.6138 - val_accuracy: 0.9406\n",
      "Epoch 19/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9624 - val_loss: 0.4267 - val_accuracy: 0.9540\n",
      "Epoch 20/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9595 - val_loss: 0.4804 - val_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "model_adam = build()\n",
    "\n",
    "model_adam.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_adam.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "predictions = model_adam.predict(X_test)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
